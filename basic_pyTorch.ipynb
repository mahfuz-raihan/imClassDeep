{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e826736-3279-4afd-bf58-2ac362d2beb8",
   "metadata": {},
   "source": [
    "# Basic of pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1f3cbc-ee1d-4392-9da1-cafcf0fa0e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Import some libaray\n",
    "import numpy as np\n",
    "import torch as tr\n",
    "\n",
    "# initializing a numpy array\n",
    "a = np.array(1)\n",
    "\n",
    "# initializing a torch array\n",
    "b = tr.tensor(1)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "268424a1-300e-4cfa-b164-65b74b6baa1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, torch.Tensor)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(a), type(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f5a681-92b3-472f-9b77-92c3a5bc7d66",
   "metadata": {},
   "source": [
    "## Mathematical operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1695227-ba7d-4851-ba40-b262422b69c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 1\n"
     ]
    }
   ],
   "source": [
    "# initializing two arrays in numpy\n",
    "a = np.array(2)\n",
    "b = np.array(1)\n",
    "print(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5970c50-ee97-4e53-8cd7-abf173b38404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "-1\n",
      "2\n",
      "2.0\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "print(a+b)\n",
    "\n",
    "# subtraction\n",
    "print(b-a)\n",
    "\n",
    "# multiplication\n",
    "print(a*b)\n",
    "\n",
    "# division\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "73ae0ea2-3842-4050-8e67-c1400f9c2560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2) tensor(1)\n",
      "tensor(3)\n",
      "tensor(-1)\n",
      "tensor(2)\n",
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "# initializing two tensors\n",
    "a = tr.tensor(2)\n",
    "b = tr.tensor(1)\n",
    "print(a,b)\n",
    "\n",
    "# addition\n",
    "print(a+b)\n",
    "\n",
    "# subtraction\n",
    "print(b-a)\n",
    "\n",
    "# multiplication\n",
    "print(a*b)\n",
    "\n",
    "# division\n",
    "print(a/b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1bdf3-502f-43a7-8ca7-b9216ed8f5a9",
   "metadata": {},
   "source": [
    "## Matrix Initialization\n",
    "Let\\'s se the matrix initilization of both parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "657a6a3a-63a1-410b-8790-2c8538498b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((3,3))\n",
    "print(a)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e6e2374-73ae-4727-99cb-aa4108a9a586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "b = tr.zeros((3,3))\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6d5560f-d7c8-403e-9f59-c72076fe55b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.88973671 -0.41359218 -0.76602601]\n",
      " [-0.92412667 -1.42159783  0.80525599]\n",
      " [ 1.14886176  1.1694284  -0.80200928]]\n"
     ]
    }
   ],
   "source": [
    "# with a random number\n",
    "# seeting the random seed for numpy\n",
    "np.random.seed(35)\n",
    "a = np.random.randn(3,3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "28233e6c-064b-48ec-8de6-0da9c271b6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3367,  0.1288,  0.2345],\n",
      "        [ 0.2303, -1.1229, -0.1863],\n",
      "        [ 2.2082, -0.6380,  0.4617]])\n"
     ]
    }
   ],
   "source": [
    "# with a random number , torch\n",
    "# seeting the random seed for torch\n",
    "tr.manual_seed(42)\n",
    "# matrix of random numbers\n",
    "b = tr.randn(3,3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b45d61-941b-4b4e-b16d-f86bde6365b5",
   "metadata": {},
   "source": [
    "## Matrix Operations\n",
    "let's have a matrix operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "82ca83bb-00e7-4ab3-824c-de9dae6d5e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.0392742  -0.60168199  0.18195878]\n",
      " [ 1.76499213 -2.14743362 -1.95905479]\n",
      " [ 1.01692529 -0.24539639 -0.15522705]] \n",
      "\n",
      "[[-0.04584589  0.32515339  1.11341829]\n",
      " [ 1.28106758  1.67912687  1.49078088]\n",
      " [ 2.14150034  1.78026585 -0.78372172]] \n",
      "\n",
      "[[-0.12814468 -0.62164688  0.21069439]\n",
      " [ 0.90133115 -0.02065676 -0.3790019 ]\n",
      " [ 1.30648762 -1.7246546  -2.20677932]] \n",
      "\n",
      "[[ 0.9155008   0.29835784 -1.39069607]\n",
      " [ 6.29449313  0.12238321  0.13573803]\n",
      " [-2.80855031 -0.75771243 -1.49396459]] \n",
      "\n",
      "[[ 0.49671415  1.52302986  1.57921282]\n",
      " [-0.1382643  -0.23415337  0.76743473]\n",
      " [ 0.64768854 -0.23413696 -0.46947439]]\n"
     ]
    }
   ],
   "source": [
    "# seeting the random seed for numpy and initializing two matrices\n",
    "np.random.seed(42)\n",
    "a = np.random.randn(3,3)\n",
    "b = np.random.randn(3,3)\n",
    "\n",
    "# matrix addition\n",
    "print(np.add(a,b), '\\n')\n",
    "\n",
    "# matrix subtraction\n",
    "print(np.subtract(a,b), '\\n')\n",
    "\n",
    "# matrix multiplication\n",
    "print(np.dot(a,b), '\\n')\n",
    "\n",
    "# matrix multiplication\n",
    "print(np.divide(a,b), '\\n')\n",
    "\n",
    "# Matrix transpose\n",
    "print(np.transpose(a))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "da069c89-5953-43c5-ab2f-a19d57ce63a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.6040,  0.6637,  1.0438],\n",
      "        [ 1.3406, -2.8127, -1.1753],\n",
      "        [ 3.1662,  0.6841,  1.2788]]) \n",
      "\n",
      "tensor([[ 0.0693, -0.4061, -0.5749],\n",
      "        [-0.8800,  0.5669,  0.8026],\n",
      "        [ 1.2502, -1.9601, -0.3555]]) \n",
      "\n",
      "tensor([[ 0.4576,  0.2724,  0.3367],\n",
      "        [-1.3636,  1.7743,  1.1446],\n",
      "        [ 0.3243,  2.8696,  2.7954]]) \n",
      "\n",
      "tensor([[ 1.2594,  0.2408,  0.2897],\n",
      "        [ 0.2075,  0.6645,  0.1884],\n",
      "        [ 2.3051, -0.4826,  0.5649]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.2303,  2.2082],\n",
       "        [ 0.1288, -1.1229, -0.6380],\n",
       "        [ 0.2345, -0.1863,  0.4617]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's try the pytorch for matries operation\n",
    "tr.manual_seed(42)\n",
    "c = tr.randn(3,3)\n",
    "d = tr.randn(3,3)\n",
    "\n",
    "# matrix operation: addition\n",
    "print(tr.add(c,d), '\\n')\n",
    "\n",
    "# matrix operation: subtraction\n",
    "print(tr.sub(c,d), '\\n')\n",
    "\n",
    "# matrix operation: multiplication\n",
    "print(tr.mm(c,d), '\\n')\n",
    "\n",
    "# matrix operation: division\n",
    "print(tr.div(c,d), '\\n')\n",
    "\n",
    "\n",
    "# matrix tranpose\n",
    "tr.t(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a91e1d0-7fcf-46e3-9120-5adbc1ce4cba",
   "metadata": {},
   "source": [
    "## Concatenating Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b1bee346-a0c4-4351-96e6-17a5e08df25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "# initializing two tensors\n",
    "a = tr.tensor([[1,2],[3,4]])\n",
    "b = tr.tensor([[5,6],[7,8]])\n",
    "print(a, '\\n')\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ada7cdb6-28ea-4858-8913-bb7dba94d4d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to concatenating vertically\n",
    "tr.cat((a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6d8a5b80-66aa-4c59-bb00-cbc8a10d5271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.cat((a,b),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f666b055-b19f-4536-b1ac-17e180e20d6c",
   "metadata": {},
   "source": [
    "## Common pyTorch Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f28b9a1c-b172-48f1-b7c0-a291bf3f97c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# iniatializing a tensor\n",
    "a = tr.ones((2,2), requires_grad=True)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0471d9e-5df1-4a2a-b030-2bd7ef3525e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[6., 6.],\n",
      "        [6., 6.]], grad_fn=<AddBackward0>) tensor(6., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# performing operations on the tensor\n",
    "\n",
    "b = a + 5\n",
    "c = b.mean()\n",
    "print(b,c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5860067c-d1d9-4964-93d7-2d896fd37812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7500, 1.7500],\n",
      "        [1.7500, 1.7500]])\n"
     ]
    }
   ],
   "source": [
    "# back propagating\n",
    "c.backward()\n",
    "\n",
    "print(a.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57738ce5-66d6-4494-b521-e2fa9114df7b",
   "metadata": {},
   "source": [
    "### Building a Neural Network from Scratch in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f67866-6b9d-439e-acf7-2c8b1af459db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 1., 0.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [0., 1., 0., 1.]]) \n",
      "\n",
      "tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "# Import tensor\n",
    "X = tr.Tensor([[1,0,1,0],[1,0,1,1],[0,1,0,1]])\n",
    "\n",
    "# output\n",
    "y = tr.Tensor([[1],[1],[0]])\n",
    "\n",
    "print(X, '\\n')\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5883760f-cf23-4ec5-a66e-0301aa97a119",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+tr.exp(-x))\n",
    "\n",
    "# derivative of sigmoid function\n",
    "def derivative_sigmoid(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34caa32b-3eac-4203-a78c-18392c563c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variable initialization\n",
    "epoch = 7000 # seeting training iterations\n",
    "\n",
    "lr = 0.1 # set learning rate\n",
    "input_layer_neurons = X.shape[1] # number of feature in dataset\n",
    "hidden_layer_neurons = 3 # number of hidden layer neurons\n",
    "output_neurons = 1 # number of neurons in output layer\n",
    "\n",
    "\n",
    "# weight and bias initialization\n",
    "wt = tr.randn(input_layer_neurons, hidden_layer_neurons).type(tr.FloatTensor)\n",
    "bi = tr.randn(1, hidden_layer_neurons).type(tr.FloatTensor)\n",
    "wtout = tr.randn(hidden_layer_neurons, output_neurons)\n",
    "biout = tr.randn(1, output_neurons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4e26ba64-bb72-4bac-aebe-d800e5d75fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(epoch):\n",
    "    # forward propagation\n",
    "    hidden_layer_input1 = tr.mm(X, wt)\n",
    "    hidden_layer_input = hidden_layer_input1 + bi\n",
    "    hidden_layer_activations = sigmoid(hidden_layer_input)\n",
    "    \n",
    "    output_layer_input1 = tr.mm(hidden_layer_activations, wtout)\n",
    "    output_layer_input = output_layer_input1 + biout\n",
    "    output = sigmoid(output_layer_input)\n",
    "    \n",
    "    # back propagation\n",
    "    E = y - output\n",
    "    slop_output_layer = derivative_sigmoid(output)\n",
    "    slop_hidden_layer = derivative_sigmoid(hidden_layer_activations)\n",
    "    d_output = E * slop_output_layer\n",
    "    \n",
    "    Error_at_hidden_layer = tr.mm(d_output, wtout.t())\n",
    "    d_hidden_layer = Error_at_hidden_layer * slop_hidden_layer\n",
    "    wtout += tr.mm(hidden_layer_activations.t(), d_output)* lr\n",
    "    biout += d_output.sum() * lr\n",
    "    wt += tr.mm(X.t(), d_hidden_layer) * lr\n",
    "    bi += d_output.sum() * lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e227967d-2732-4c8e-b9fc-f4028efc248f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:\n",
      " tensor([[1.],\n",
      "        [1.],\n",
      "        [0.]]) \n",
      "\n",
      "predicted:\n",
      " tensor([[0.9984],\n",
      "        [0.9972],\n",
      "        [0.0050]])\n"
     ]
    }
   ],
   "source": [
    "print('actual:\\n', y,'\\n')\n",
    "print('predicted:\\n', output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b28d3d7b-fbf0-4018-832d-2413d320626d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tr.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608e8228-1f73-4059-8cd1-03b18ea0a2fe",
   "metadata": {},
   "source": [
    "### Opeation on gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f796d620-110a-4100-9308-227dade304d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.8721,  0.9826, -0.9442, -0.9234,  0.2177], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import torch as tr\n",
    "import numpy as np\n",
    "\n",
    "if tr.cuda.is_available():\n",
    "    device = tr.device('cuda')\n",
    "    x = tr.randn(5, device=device)\n",
    "    y = tr.randn(5)\n",
    "    \n",
    "    y = y.to(device)\n",
    "    z = x*y\n",
    "    print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74149667-2738-4fea-8c88-20fce0a1265a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    " if tr.cuda.is_available():\n",
    "        a = tr.ones(5, requires_grad=True)\n",
    "        print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a67258-5747-43ff-ab9c-25250c3a7966",
   "metadata": {},
   "source": [
    "### Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c48ee4e2-42ce-4af4-8131-512b6ab144e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x is:  tensor([-1.0213, -1.9190,  0.5424], requires_grad=True)\n",
      "y is:  tensor([0.9787, 0.0810, 2.5424], grad_fn=<AddBackward0>)\n",
      "z is:  tensor([2.0861, 7.3653, 0.5883], grad_fn=<MulBackward0>)\n",
      "z1:  tensor(3.3466, grad_fn=<MeanBackward0>)\n",
      "tensor([-1.3617, -2.5587,  0.7232])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n- x.requires_grad(False)\\n- x.detach()\\n- with torch.no_grad()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as tr\n",
    "\n",
    "if tr.cuda.is_available():\n",
    "    x = tr.randn(3, requires_grad=True)\n",
    "    print('x is: ', x)\n",
    "    y = x + 2\n",
    "    print('y is: ', y)\n",
    "    \n",
    "    z = x*x*2\n",
    "    print('z is: ', z)\n",
    "    \n",
    "    z = z.mean()\n",
    "    print('z1: ', z)\n",
    "    \n",
    "    z.backward()\n",
    "    print(x.grad)\n",
    "\n",
    "    \n",
    "# how to prevent grad from the formulas\n",
    "'''\n",
    "- x.requires_grad(False)\n",
    "- x.detach()\n",
    "- with torch.no_grad()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0295044-e3bc-4459-8a2b-f72f6b37ed45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor(12., grad_fn=<SumBackward0>)\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "# an example of autograd\n",
    "if tr.cuda.is_available():\n",
    "    weight = tr.ones(4, requires_grad=True)\n",
    "    \n",
    "    for epach in range(3):\n",
    "        model_output = (weight*3).sum()\n",
    "        model_output.backward()\n",
    "        \n",
    "        print(model_output)\n",
    "        print(weight.grad)\n",
    "        \n",
    "        #weight.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfad310-549a-44c1-bcc7-1236569dc2c2",
   "metadata": {},
   "source": [
    "### backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe5c1768-9200-426e-858b-80224282bb6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "x = tr.tensor(1.0)\n",
    "y = tr.tensor(2.0)\n",
    "\n",
    "w = tr.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_predict = w*x\n",
    "loss = (y_predict - y)**2\n",
    "print(loss)\n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "42679e0f-b8bf-483a-a58a-3302536af694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict (before training) 4 tensor(4.)\n",
      "\tgrad:  1.0 2.0 tensor(-2.)\n",
      "\tgrad:  2.0 4.0 tensor(-7.8400)\n",
      "\tgrad:  3.0 6.0 tensor(-16.2288)\n",
      "Progress: 0 tensor(7.3159)\n",
      "\tgrad:  1.0 2.0 tensor(-1.4786)\n",
      "\tgrad:  2.0 4.0 tensor(-5.7962)\n",
      "\tgrad:  3.0 6.0 tensor(-11.9981)\n",
      "Progress: 1 tensor(3.9988)\n",
      "\tgrad:  1.0 2.0 tensor(-1.0932)\n",
      "\tgrad:  2.0 4.0 tensor(-4.2852)\n",
      "\tgrad:  3.0 6.0 tensor(-8.8704)\n",
      "Progress: 2 tensor(2.1857)\n",
      "\tgrad:  1.0 2.0 tensor(-0.8082)\n",
      "\tgrad:  2.0 4.0 tensor(-3.1681)\n",
      "\tgrad:  3.0 6.0 tensor(-6.5580)\n",
      "Progress: 3 tensor(1.1946)\n",
      "\tgrad:  1.0 2.0 tensor(-0.5975)\n",
      "\tgrad:  2.0 4.0 tensor(-2.3422)\n",
      "\tgrad:  3.0 6.0 tensor(-4.8484)\n",
      "Progress: 4 tensor(0.6530)\n",
      "\tgrad:  1.0 2.0 tensor(-0.4417)\n",
      "\tgrad:  2.0 4.0 tensor(-1.7316)\n",
      "\tgrad:  3.0 6.0 tensor(-3.5845)\n",
      "Progress: 5 tensor(0.3569)\n",
      "\tgrad:  1.0 2.0 tensor(-0.3266)\n",
      "\tgrad:  2.0 4.0 tensor(-1.2802)\n",
      "\tgrad:  3.0 6.0 tensor(-2.6500)\n",
      "Progress: 6 tensor(0.1951)\n",
      "\tgrad:  1.0 2.0 tensor(-0.2414)\n",
      "\tgrad:  2.0 4.0 tensor(-0.9465)\n",
      "\tgrad:  3.0 6.0 tensor(-1.9592)\n",
      "Progress: 7 tensor(0.1066)\n",
      "\tgrad:  1.0 2.0 tensor(-0.1785)\n",
      "\tgrad:  2.0 4.0 tensor(-0.6997)\n",
      "\tgrad:  3.0 6.0 tensor(-1.4485)\n",
      "Progress: 8 tensor(0.0583)\n",
      "\tgrad:  1.0 2.0 tensor(-0.1320)\n",
      "\tgrad:  2.0 4.0 tensor(-0.5173)\n",
      "\tgrad:  3.0 6.0 tensor(-1.0709)\n",
      "Progress: 9 tensor(0.0319)\n",
      "Predict (after training) 4 tensor(7.8049)\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "x_data = [1.0, 2.0, 3.0]\n",
    "y_data = [2.0, 4.0, 6.0]\n",
    "\n",
    "w = Variable(tr.Tensor([1.0]), requires_grad=True)\n",
    "\n",
    "# our model forward pass\n",
    "def forward(x):\n",
    "    return x * w\n",
    "\n",
    "# loss function\n",
    "def loss(x, y):\n",
    "    y_pred = forward(x)\n",
    "    \n",
    "    return (y_pred - y)**2\n",
    "\n",
    "# before training\n",
    "print(\"predict (before training)\", 4, forward(4).data[0])\n",
    "\n",
    "# training lossp\n",
    "for epach in range(10):\n",
    "    for x_val, y_val in zip(x_data,y_data):\n",
    "        l = loss(x_val, y_val)\n",
    "        l.backward()\n",
    "        \n",
    "        print(\"\\tgrad: \", x_val, y_val, w.grad.data[0])\n",
    "        w.data = w.data - 0.01 * w.grad.data\n",
    "        \n",
    "        # manually zero the gradiants after updaring weights\n",
    "        w.grad.data.zero_()\n",
    "        \n",
    "    print(\"Progress:\", epach, l.data[0])\n",
    "\n",
    "# after training\n",
    "print(\"Predict (after training)\", 4, forward(4).data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3acd5b-58af-4a10-86ce-da5c3c064e5d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
